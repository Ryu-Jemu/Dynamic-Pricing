# ================================================================
# 5G O-RAN 1-Cell  ·  3-Part Tariff  ·  2 Slices  ·  SB3 SAC
# ================================================================
# REVISION 9 (v9) — Design improvements from verification report
#
# New in v9:
#   [D1] NSACF admission control           [3GPP TS 23.501 §5.2.3; Caballero JSAC 2019]
#   [D2] Hierarchical action timing         [Vezhnevets ICML 2017; Bacon AAAI 2017]
#   [D3] Hard capacity guard                [3GPP TS 23.501 §5.15; Samdanis CommMag 2016]
#   [D4] Segment proportions grounded       [Kim & Yoon Expert Syst 2004; KISDI 2023]
#   [D5] Observation dim 22 → 24           [Dulac-Arnold JMLR 2021]
#   CMDP framing                            [Altman 1999; Berry RAND 1994]
#
# v8 changes:
#   [M1] total_timesteps 10K→1M            [Haarnoja 2018; Henderson 2018]
#   [M2] Curriculum fraction-based          [Narvekar 2020; Bengio 2009]
#   [M3] Convex SLA penalty (λ_E 50K→200K) [Tessler 2019; Paternain 2019]
#   [M4] rho_U_max 0.60→0.35→0.45 [D1]   [Huang IoT-J 2020; 3GPP TS 23.501]
#   [M5] beta_pop 0.1→0.3                 [Mguni 2019; Zheng 2022]
#   [M6] Lagrangian safety layer           [Tessler 2019; Stooke 2020]
#   [M7] train_freq/gradient_steps 1→4    [Fedus 2020]
#
# Prior revisions (v1–v7):
#   [E1–E9] Feature engineering, CLV, multi-seed
#   [C1–C5] Calibration fixes
#   [R1–R8] Training / observation / reward improvements
# ================================================================

# ── §3.1  Time axis ──
# [EP1] episode_cycles 24→1, episode_mode continuous  [Pardo ICML 2018; Wan arXiv 2025]
# 1-cycle episodes with truncated=True; population state persists across resets.
# CLV 24-month horizon is post-hoc (eval.py chains 24 episodes per repeat).
time:
  steps_per_cycle: 30
  episode_cycles: 1               # [EP1] 24→1  [Pardo 2018; Wan 2025]
  episode_mode: "continuous"      # [EP1] "continuous" or "episodic" (legacy)

# ── §4  Action bounds (5-D continuous) ──
# [PR-BOUNDS] Korean 5G market calibration [SKT/KT 2024; ITU DDI 2023]
action:
  F_U_min: 30000.0                # KT 슬림 4GB 30K [KT 2024]
  F_U_max: 90000.0                # SKT 프라임 89K [SKT 2024]
  F_E_min: 35000.0                # [PR-BOUNDS] 40K→35K  [SKT 컴팩트 39K, 다이렉트 27K]
  F_E_max: 110000.0               # [PR-BOUNDS] 150K→110K [SKT 프리미엄 109K; WTP P99]
  p_over_U_min: 500.0
  p_over_U_max: 5000.0
  p_over_E_min: 500.0             # [PR-BOUNDS] 200→500 [Tirole 1988: marginal cost floor]
  p_over_E_max: 3000.0
  rho_U_min: 0.03              # [FIX-M1] 0.05→0.03; C_U=14.4GB (1.2× URLLC load)
  rho_U_max: 0.12              # [FIX-M1] 0.20→0.12; C_E≥352GB guaranteed
                                # URLLC load ~12GB, C_U at rho=0.12 = 57.6GB (4.8× headroom)
                                # [Dulac-Arnold JMLR 2021 Challenge #6; Sciancalepore TNSM 2019]

# ── §5  3-Part tariff allowances ──
# Q_U=5GB: Korean URLLC average  [MSIT 2023; ITU DDI 2023]
# Q_E=50GB: Korean eMBB 5G average  [KCC 2023; KISDI ICT 2023]
tariff:
  Q_U_gb: 5.0
  Q_E_gb: 50.0

# ── §6  Traffic ──
traffic:
  URLLC:
    target_p50_gb_day: 0.15
    target_p90_gb_day: 0.50
    D_min_gb: 0.001
    D_max_gb: 5.0
  eMBB:
    target_p50_gb_day: 1.5
    target_p90_gb_day: 5.0
    D_min_gb: 0.01
    D_max_gb: 50.0

# ── §6b  Demand-price elasticity  [C4] ──
demand_elasticity:
  enabled: true
  epsilon_U: 0.15               # [Nevo et al. Econometrica 2016]
  epsilon_E: 0.30
  p_ref_U: 2500.0
  p_ref_E: 1500.0
  floor: 0.5

# ── §7  RAN / PRB capacity ──
# C_total=400GB: 100MHz NR, 273 PRBs  [3GPP TS 38.306 R16]
# kappa_U=1.2: URLLC scheduling gain  [3GPP TR 38.913 §7.1; Bennis IEEE Comms 2018]
# bandwidth_mhz=100, scs_khz=30, prb_total=273 → C_total derivation only
radio:
  C_total_gb_per_step: 400.0       # Derived: 100MHz NR, 273 PRBs [3GPP TS 38.306 R16]
  kappa_U: 1.2

# ── §8  QoS / SLA violation ──
qos:
  alpha_congestion: 10.0
  lambda_U: 500000.0
  lambda_E: 500000.0            # [D3] 200K→500K  [Tessler 2019; KCC 2023]
  gamma_sla_E: 3.0              # [F2] 4.0→3.0 revert; γ=4 weakens penalty at pviol_E=0.2 by 5× vs γ=3
                                 # [Bertsekas 1996 §6.3; Paternain TAC 2022 §IV]

# ── §9  Cost (Capex excluded) ──
cost:
  c_opex_per_user: 1200.0
  c_energy_per_gb: 50.0
  c_cac_per_join: 80000.0

# ── §10  Market — join / churn ──
# [PR-1] price_norm REMOVED; per-slice F_s/F_s_max normalization [Train 2009; Anderson et al. 1992]
# [PR-2] Bill shock mechanism [Grubb & Osborne AER 2015]
market:
  beta0_churn: -5.5
  beta_p_churn: 3.0
  beta_q_churn: 2.0
  beta_sw_churn: 1.5
  beta_bill_shock: 1.0            # [PR-2] Bill shock → churn coefficient
  bill_shock_threshold: 1.5       # [PR-2] Triggers when actual_bill/base_fee > 1.5
  beta0_join: -7.0
  beta_p_join: 1.0
  beta_q_join: 1.5
  beta_p_over_join: 0.3           # [PR-4] Overage price dampens joins [Nevo et al. 2016]
  mode: "stochastic"
  # price_norm: 120000.0          # [PR-3] REMOVED → replaced by per-slice normalization

# ── §11  CLV ──
clv:
  horizon_months: 24
  discount_rate_monthly: 0.01
  enabled: true

# ── §11b  CLV-aware reward shaping ──
clv_reward_shaping:
  enabled: true
  alpha_retention: 2.0
  warmup_steps: 0              # [EP1] 100→0; uses _total_steps internally

# ── §13  Population ──
# N_total=500: single gNB suburban cell  [3GPP TR 38.913 §6.1 Table 6.1-1]
# Segment proportions: [D4]
#   30% price-sensitive: consistent with Korean postpaid value-tier share
#     [Kim & Yoon, Expert Syst. Appl. 2004; KISDI ICT Outlook 2023]
#   45% balanced: majority moderate-usage subscribers
#     [Ericsson Mobility Report 2023, Figure 12]
#   25% QoS-sensitive: premium/enterprise tier
#     [GSMA Intelligence 2023; Shy, Rev. Industrial Org. 2002]
# Switching costs: [Shy 2002; Kim et al. Info Econ & Policy 2004]
population:
  N_total: 500
  N_active_init: 200
  frac_urllc: 0.20
  segments:
    names: ["price_sensitive", "balanced", "qos_sensitive"]
    proportions: [0.30, 0.45, 0.25]
    price_sensitivity:   { price_sensitive: 1.5, balanced: 1.0, qos_sensitive: 0.6 }
    qos_sensitivity:     { price_sensitive: 0.5, balanced: 1.0, qos_sensitive: 1.8 }
    switching_cost:      { price_sensitive: 0.3, balanced: 0.5, qos_sensitive: 0.8 }

# ── §12  Training ──
training:
  total_timesteps: 100000            # [OPT] 1M→100K (개발용 축소)
  learning_rate: 0.0003
  learning_rate_end: 0.00001
  lr_schedule: "linear"
  batch_size: 512                   # [OPT-D] 256→512 GPU 활용도 향상  [Fedus 2020]
  buffer_size: 50000                # [OPT] 200K→50K (개발용 축소)
  gamma: 0.995
  tau: 0.005
  ent_coef: "auto"
  ent_coef_init: 0.5
  target_entropy: -3.0           # [I-6a] -5(default) → -3.0  [Haarnoja ICML 2018 §5; Zhou ICLR 2022]
  train_freq: 4                 # [M7]  [Fedus 2020]
  gradient_steps: 2             # [OPT-D] 4→2; 총 gradient 계산량 유지 (2×512=4×256)  [Fedus 2020]
  eval_freq: 20000              # [OPT-E] 10K→20K; 평가 간격 2배
  n_eval_episodes: 10            # [OPT-E] 20→10; 에피소드 수 절반
  n_seeds: 1                        # [OPT] 5→1 (개발용 축소)
  parallel_seeds: false          # [OPT-A] 다중 seed 병렬 실행  [Henderson 2018]
  max_parallel: 5                # [OPT-A] 최대 동시 프로세스 수
  curriculum:
    enabled: true
    # [D5] 3-phase curriculum  [Narvekar 2020; Bengio 2009; Achiam 2017]
    phases:
      - fraction: 0.15          # Phase 1: pricing/capacity isolation (no churn/join)
        churn_join: false
        lagrangian_boost: 0.0
      - fraction: 0.25          # Phase 2: QoS-focused with boosted Lagrangian
        churn_join: true
        lagrangian_boost: 2.0
      - fraction: 0.60          # Phase 3: full optimization
        churn_join: true
        lagrangian_boost: 1.0
  # [OPT-C] Early stopping  [Prechelt 2002; Henderson 2018]
  # [ME-5] min_timesteps = 60% × total_timesteps = Phase 3 시작(40%) + 20% 추가 학습 보장
  early_stopping:
    enabled: true
    patience: 15               # [V11-6] 10→15  [Henderson AAAI 2018]
    min_timesteps: 75000       # [V11-6] 60K→75K; 0.75 × 100K  [Prechelt 2002]
    min_improvement: 0.01      # 1% 상대 개선 임계값

# ── §3.2  Observation  [ME-1] 23-D ──
# [ME-1] 24D→23D: removed obs[1] (inactive fraction = 1 - obs[0], linearly dependent)
# [Dulac-Arnold JMLR 2021] — minimize observation dimensionality for sample efficiency
observation:
  dim: 23                       # [ME-1] 24→23; [D5][D6] pviol_E EMA + load headroom
  clip_min: -10.0
  clip_max: 10.0

# ── §15b  Action smoothing ──
action_smoothing:
  enabled: true
  weight: 0.05
  weights: [0.10, 0.05, 0.10, 0.05, 0.05]   # [I-3a] rho_U: 0.01→0.05  [Dalal NeurIPS 2018 §4.1; downstream C_E impact]

# ── §15c  Population-aware reward ──
population_reward:
  enabled: true
  beta_pop: 0.6                 # [V11-2] 0.3→0.6  [Mguni 2019 §4.2; Zheng 2022 ExtData Fig.3]
  target_ratio: 0.4
  quadratic: true               # [V11-8] Asymmetric quadratic  [Zheng 2022; Mguni 2019]

# ── §15d  Lagrangian QoS constraint  [M6][D2] ──
# [D2] PID control replaces simple dual ascent  [Stooke ICLR 2020]
lagrangian_qos:
  enabled: true
  pviol_E_threshold: 0.10       # [F3] 0.15→0.10; train-eval robustness margin  [Tobin IROS 2017; Rajeswaran NeurIPS 2017]
  Kp: 0.05                      # [D2] Proportional gain  [Stooke 2020]
  Ki: 0.02                      # [F4] 0.005→0.02; 4× increase for timely constraint enforcement  [Stooke 2020; Mao 2025]
  Kd: 0.01                      # [D2] Derivative gain
  lambda_max: 10.0               # [D2] 5.0→10.0  [Boyd 2004]
  lambda_min: 0.5                # [FIX-M3] 0.1→0.5; penalty at pviol=0.2: 0.5×0.1=0.05 (2.8% of reward range)  [Paternain CDC 2019; TAC 2022]
  update_freq: 200               # [D2] 1000→200  [Stooke 2020]
  eval_lambda_floor: 1.0         # [FIX-C3] Minimum λ during eval  [Tessler 2019 §5; Tobin IROS 2017]

# ── §16  [D1] Admission control (NSACF) ──
# [3GPP TS 23.501 §5.2.3; Caballero et al. IEEE JSAC 2019]
# Gating: reject new joins if projected load > threshold or pviol > ceiling
admission_control:
  enabled: true
  load_threshold: 0.92          # [V11-3] 0.85→0.92  [Samdanis CommMag 2016]
  pviol_ceiling: 0.50           # [V11-3] 0.30→0.50  [Caballero JSAC 2019]
  per_user_load_estimate_E_gb: 1.5    # eMBB p50 daily traffic
  per_user_load_estimate_U_gb: 0.15   # URLLC p50 daily traffic

# ── §17  [D2] Hierarchical action timing ──
# [Vezhnevets et al. ICML 2017; Bacon et al. AAAI 2017]
# Pricing locked at cycle start; rho_U updates every step
hierarchical_actions:
  enabled: true

# ── §18  [I-3b] eMBB Capacity Guard ──
# Soft penalty when L_E/C_E exceeds threshold
# [3GPP TS 23.501 §5.15.7; Samdanis CommMag 2016; Huang IoT-J 2020]
capacity_guard:
  enabled: true
  embb_load_ratio_max: 0.85      # [FIX-M2] 0.95→0.85; activates near operating point  [3GPP TS 23.501 §5.15.7]
  penalty_scale: 0.10            # [FIX-M2] 0.02→0.10; 5× for meaningful gradient  [Samdanis CommMag 2016]

# ── §19  [I-5a] SLA Awareness Penalty ──
# Additional reward shaping when SLA penalty exceeds revenue threshold
# [Wiewiora ICML 2003; Ng ICML 1999]
sla_awareness:
  enabled: true
  revenue_ratio_threshold: 0.05  # Trigger when sla_penalty/revenue > 5%
  penalty_scale: 0.1             # Penalty coefficient

# ── Calibration targets ──
calibration:
  churn_target_monthly: 0.03