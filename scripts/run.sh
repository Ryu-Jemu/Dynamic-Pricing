#!/usr/bin/env bash
# ==============================================================================
# O-RAN 3-Part Tariff Pricing — End-to-End Pipeline  (Requirement 15)
#
# REVISION 10 — v10 pipeline:
#   [R1] 1M training timesteps (restored)
#   [R3] Curriculum learning (Phase 1: no churn/join; Phase 2: full dynamics)
#   [R8] Higher initial entropy coefficient
#   [M15] Dashboard generation integrated into eval.py (Step 4)
#   Prior: [E9] Multi-seed training, [F1] transparent pip, [F2] SB3 verify
#
# Steps:
#   0) Create venv & install dependencies
#   1) Generate synthetic user CSV
#   2) Run unit tests
#   3) Train SAC agent (multi-seed with curriculum)
#   4) Evaluate & export logs + CLV + dashboards [M15]
#
# Usage:
#   chmod +x scripts/run.sh && ./scripts/run.sh [--seeds N]
# ==============================================================================
set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_DIR="$(dirname "$SCRIPT_DIR")"
cd "$PROJECT_DIR"

# Parse optional --seeds argument
N_SEEDS=""
while [[ $# -gt 0 ]]; do
    case $1 in
        --seeds) N_SEEDS="$2"; shift 2;;
        *) shift;;
    esac
done

echo "============================================"
echo " O-RAN 3-Part Tariff — Full Pipeline (v10)"
echo "============================================"
echo "Project dir: $PROJECT_DIR"
echo ""

# ── Step 0: Clean environment ──
echo "===== Step 0: Environment Setup ====="
echo "Cleaning previous caches..."
find . -type d -name "__pycache__" -not -path "./.git/*" -exec rm -rf {} + 2>/dev/null || true
rm -rf .pytest_cache
echo "  Removed __pycache__ and .pytest_cache"

echo "Recreating virtual environment..."
rm -rf .venv
python3 -m venv .venv
source .venv/bin/activate
pip install --upgrade pip -q

echo "Installing dependencies..."
pip install -r requirements.txt 2>&1 | tee /tmp/pip_install.log | tail -5
echo ""

# Verify critical packages
echo "Verifying critical packages..."
python -c "
import sys
errors = []

try:
    import stable_baselines3
    print(f'  stable-baselines3 {stable_baselines3.__version__}')
except ImportError as e:
    errors.append(f'stable-baselines3: {e}')
    print(f'  stable-baselines3 MISSING: {e}')

try:
    import torch
    from oran3pt.utils import select_device
    dev = select_device()
    print(f'  torch {torch.__version__} (device: {dev})')
except ImportError as e:
    errors.append(f'torch: {e}')
    print(f'  torch MISSING: {e}')

try:
    import gymnasium
    print(f'  gymnasium {gymnasium.__version__}')
except ImportError as e:
    errors.append(f'gymnasium: {e}')
    print(f'  gymnasium MISSING: {e}')

if errors:
    print()
    print('  Some packages failed. Attempting targeted install...')
    sys.exit(1)
else:
    print('  All critical packages verified.')
" || {
    echo ""
    echo "Attempting targeted SB3 install..."
    pip install "stable-baselines3[extra]>=2.3.0" --force-reinstall 2>&1 | tail -5
    python -c "import stable_baselines3; print(f'  SB3 {stable_baselines3.__version__} installed')" || {
        echo "  SB3 install failed. Training will use random baseline."
    }
}
echo ""

# ── Step 1: Generate user CSV ──
echo "===== Step 1: Generate Users ====="
python -m oran3pt.gen_users \
    --config config/default.yaml \
    --output data/users_init.csv
echo ""

# ── Step 2: Unit tests ──
echo "===== Step 2: Unit Tests ====="
python -m pytest tests/ -v --tb=short || echo "WARNING: Some tests failed (continuing)"
echo ""

# ── Step 3: Train SAC ──
echo "===== Step 3: Train SAC ====="
TRAIN_ARGS="--config config/default.yaml --users data/users_init.csv"
if [ -n "$N_SEEDS" ]; then
    TRAIN_ARGS="$TRAIN_ARGS --seeds $N_SEEDS"
fi
python -m oran3pt.train $TRAIN_ARGS
echo ""

# ── Step 4: Evaluate ──
echo "===== Step 4: Evaluation ====="
MODEL_PATH="outputs/best_model.zip"
if [ -f "$MODEL_PATH" ]; then
    echo "Found trained model: $MODEL_PATH"
    python -m oran3pt.eval \
        --config config/default.yaml \
        --users data/users_init.csv \
        --model "$MODEL_PATH" \
        --repeats 5
else
    echo "No trained model found at $MODEL_PATH"
    echo "Evaluating with random policy (baseline only)"
    python -m oran3pt.eval \
        --config config/default.yaml \
        --users data/users_init.csv \
        --repeats 5
fi
echo ""

# [M15] Dashboards are now auto-generated by eval.py (Step 4).
# For interactive Streamlit dashboard, run separately:
#   streamlit run oran3pt/dashboard_app.py -- --data outputs/rollout_log.csv

echo "============================================"
echo " Pipeline complete.  Outputs: $PROJECT_DIR/outputs/"
echo "============================================"
echo ""
echo " Files:"
ls -lh outputs/ 2>/dev/null || echo "  (no outputs yet)"
